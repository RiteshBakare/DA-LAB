{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqMnifweT80c3mK4S36KSl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkmpagdd_DIl","executionInfo":{"status":"ok","timestamp":1718003505775,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}},"outputId":"1e947a1d-fc3d-4c0c-d9ae-62e35e9b60ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I love sunny days! They make me feel so happy.',\n"," \"I'm feeling sad today because it's raining.\",\n"," \"I'm not sure how I feel about this weather.\",\n"," 'The movie was fantastic! I enjoyed every moment of it.',\n"," 'The food was terrible, I would not recommend this restaurant.']"]},"metadata":{},"execution_count":1}],"source":["data = [\n","    \"I love sunny days! They make me feel so happy.\",\n","    \"I'm feeling sad today because it's raining.\",\n","    \"I'm not sure how I feel about this weather.\",\n","    \"The movie was fantastic! I enjoyed every moment of it.\",\n","    \"The food was terrible, I would not recommend this restaurant.\"\n","]\n","data"]},{"cell_type":"code","source":["!pip install nltk textblob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cyr_BOth_NnT","executionInfo":{"status":"ok","timestamp":1718003523141,"user_tz":-330,"elapsed":9573,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}},"outputId":"01e00b75-3893-4336-d1da-a55736abc601"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from textblob import TextBlob\n","\n","# Download required NLTK data files\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7Lc8Mc2_TVN","executionInfo":{"status":"ok","timestamp":1718003547921,"user_tz":-330,"elapsed":4696,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}},"outputId":"2b303da3-26e5-4c39-c202-cd6234c201f4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Initialize stopwords and stemmer\n","stop_words = set(stopwords.words('english'))\n","ps = PorterStemmer()"],"metadata":{"id":"izW9QI9D_afo","executionInfo":{"status":"ok","timestamp":1718003562810,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Function for text preprocessing\n","def preprocess_text(text):\n","    # Tokenization\n","    tokens = word_tokenize(text)\n","    # Convert to lower case\n","    tokens = [word.lower() for word in tokens]\n","    # Remove stopwords and perform stemming\n","    filtered_tokens = [ps.stem(word) for word in tokens if word.isalnum() and word not in stop_words]\n","    return filtered_tokens"],"metadata":{"id":"TiW4qtyk_fSn","executionInfo":{"status":"ok","timestamp":1718003572932,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Preprocess each text in the dataset\n","preprocessed_data = [preprocess_text(text) for text in data]"],"metadata":{"id":"QXDgFewh_hoW","executionInfo":{"status":"ok","timestamp":1718003584250,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function for sentiment analysis\n","def analyze_sentiment(text):\n","    blob = TextBlob(text)\n","    return blob.sentiment"],"metadata":{"id":"eOIRaQ7e_ke1","executionInfo":{"status":"ok","timestamp":1718003599761,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Perform sentiment analysis on the original data\n","sentiment_analysis = [analyze_sentiment(text) for text in data]"],"metadata":{"id":"oT-yOAEH_oUN","executionInfo":{"status":"ok","timestamp":1718003608919,"user_tz":-330,"elapsed":5,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Output the results\n","for i, text in enumerate(data):\n","    print(f\"Original Text: {text}\")\n","    print(f\"Preprocessed Text: {preprocessed_data[i]}\")\n","    print(f\"Sentiment Analysis: {sentiment_analysis[i]}\")\n","    print(\"-\" * 50)"],"metadata":{"id":"L3Vq15ch_qhZ","executionInfo":{"status":"ok","timestamp":1718003616102,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ritesh bakare","userId":"13307637582896466871"}},"outputId":"7b4c6a1f-501b-481e-b1ea-88070b3c1433","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text: I love sunny days! They make me feel so happy.\n","Preprocessed Text: ['love', 'sunni', 'day', 'make', 'feel', 'happi']\n","Sentiment Analysis: Sentiment(polarity=0.7125, subjectivity=0.8)\n","--------------------------------------------------\n","Original Text: I'm feeling sad today because it's raining.\n","Preprocessed Text: ['feel', 'sad', 'today', 'rain']\n","Sentiment Analysis: Sentiment(polarity=-0.5, subjectivity=1.0)\n","--------------------------------------------------\n","Original Text: I'm not sure how I feel about this weather.\n","Preprocessed Text: ['sure', 'feel', 'weather']\n","Sentiment Analysis: Sentiment(polarity=-0.25, subjectivity=0.8888888888888888)\n","--------------------------------------------------\n","Original Text: The movie was fantastic! I enjoyed every moment of it.\n","Preprocessed Text: ['movi', 'fantast', 'enjoy', 'everi', 'moment']\n","Sentiment Analysis: Sentiment(polarity=0.5, subjectivity=0.8)\n","--------------------------------------------------\n","Original Text: The food was terrible, I would not recommend this restaurant.\n","Preprocessed Text: ['food', 'terribl', 'would', 'recommend', 'restaur']\n","Sentiment Analysis: Sentiment(polarity=-1.0, subjectivity=1.0)\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y3DWnVDa_sUg"},"execution_count":null,"outputs":[]}]}